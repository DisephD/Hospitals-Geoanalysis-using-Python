# -*- coding: utf-8 -*-
"""Data Manipulation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WEVVSYYncAJJCfdCWCaAu_8i74C1mZNr

# **Data Manipulation**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import geopandas as gpd
import re
import folium
import pprint
from scipy.stats import chi2_contingency
from scipy.stats import fisher_exact
from shapely.geometry import Point
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline
# %reload_ext autoreload
# %autoreload 2

nigeria = gpd.read_file("/content/ngaadmbndaadm1osgof20161215.geojson")
nigeria.admin1Name = nigeria.admin1Name.str.replace("Federal Capital Territory", "FCT")
nigeria.admin1Name = nigeria.admin1Name.str.replace("Akwa Ibom", "Akwa-Ibom")

nig_hospital_data = pd.read_excel("/content/nigeria-hospitals-and-clinics-hxl-xlsx-1.xlsx")
nig_hospital_data.head()

df = nig_hospital_data.drop(axis= 0, index= 0)
df.info()

"""I transformed the year column as a datetime in the form of yyyy-mm--dd"""

df.start_date = pd.to_datetime(df.start_date, errors = "coerce", yearfirst= True, dayfirst= False)

"""So I continued cleaning the data"""

df.drop_duplicates(keep= "first", inplace = True)
df.fillna(np.nan, inplace = True)
df.uid.nunique()
df.head()

special_char= r'[^\w\s]'
df[df.state.str.contains(special_char, regex= True)]
#df.isna().sum().plot(kind = "bar")

"""Because the data contains geographical information, I'd have to process as a geodataframe"""

gdf = gpd.GeoDataFrame(df)
gdf[gdf.columns[gdf.eq('').any()]]
# gdf[gdf.latitude== ""]

"""After confirming there was no empty column in the latitude column, I searched for special characters "." because I kept getting an error when I tried to store it as an integer eg "8..48" "7,383"
"""

gdf[gdf.latitude.astype(str).str.contains("..")]

"""This method didn't give me the output I was looking for so I had to use a regular expression to search for the patterns, and also remove whitespaces."""

gdf.longitude = gdf.longitude.astype(str).apply(lambda x: re.sub(r'\.{2,}','.',x))
gdf.latitude = gdf.latitude.astype(str).apply(lambda x: re.sub(r'\.{2,}','.',x))
gdf.latitude = gdf.latitude.astype(str).str.replace("`","").str.replace(":","").str.strip()
gdf.longitude = gdf.longitude.astype(str).str.replace(",","").str.strip()

"""That was successful. So I formatted the two geographic columns as integers and converted them to geometric points on EPSG 4326; The coordinate system used on Google Earth and wikipedia."""

gdf.latitude = pd.to_numeric (gdf.latitude, errors = "coerce")
gdf.longitude = pd.to_numeric (gdf.longitude, errors = "coerce")
gdf.geometry = gdf.apply(lambda x: Point (float(x.longitude), float(x.latitude)), axis = 1)
gdf= gpd.GeoDataFrame(gdf,geometry ="geometry", crs="epsg:4326")
gdf.head()

"""Then I created a column for regions."""

regions= [{"region": "North Central", "states": ['Niger', 'Kwara', 'Nasarawa', 'Benue', 'Kogi','FCT']},
          {"region": "North East", "states": ['Yobe', 'Borno', 'Gombe', 'Bauchi', 'Adamawa', 'Taraba']},
          {"region": "North West", "states": ['Sokoto', 'Kebbi', 'Zamfara', 'Katsina', 'Kano','Jigawa', 'Kaduna']},
          {"region": "South West", "states": ['Oyo', 'Osun', 'Ekiti', 'Ondo','Ogun', 'Lagos']},
          {"region": "South East", "states": ['Enugu', 'Ebonyi', 'Anambra', 'Imo', 'Abia']},
          {"region": "South South", "states": ['Edo', 'Delta', 'Bayelsa', 'Rivers', 'Akwa-Ibom', 'Cross River']}]

# Create an empty list to store the data for the new DataFrame
nig_regions_data = []

for region in regions:
    for state in region['states']:
        nig_regions_data.append({'region': region['region'], 'reg_state': state})

# Create the DataFrame from the list of dictionaries
nig_regions = pd.DataFrame(nig_regions_data)

gdf= gdf.merge(nig_regions, how = "left", left_on= "state", right_on = "reg_state")
gdf= gdf.drop("reg_state",axis=1)

"""I created another column but this time with latitude coming first because some Pandas geographic operations would need it stored this way and some others the other way."""

filtered_gdf = gdf[~(gdf.latitude.isna() | gdf.longitude.isna())]
def switch_coords (point):
  if not point.is_empty:
    return Point (point.y, point.x)
  else:
    return point

filtered_gdf["lat_lng"] = filtered_gdf.geometry.apply(switch_coords)
filtered_gdf

"""Lastly I calulated the average geographic distance of clustered hospitals to each other."""

from geopy.distance import geodesic
from sklearn.cluster import MiniBatchKMeans
from itertools import combinations
from multiprocessing import Pool, cpu_count

# Calculate distances for a pair of hospitals
def calculate_distances(pair):
    return geodesic(pair[0], pair[1]).miles

# Calculate distances for each state
def calculate_state_distances(state, operational_hospitals):
    state_hospitals = operational_hospitals[operational_hospitals['state'] == state]
    lat_lng = state_hospitals[['latitude', 'longitude']].values

    # Cluster hospitals to reduce the number of distance calculations
    kmeans = MiniBatchKMeans(n_clusters=min(len(lat_lng) // 10, 15), batch_size=1000, random_state=42).fit(lat_lng)
    cluster_centers = kmeans.cluster_centers_

    pairs = list(combinations(cluster_centers, 2))

    # I'll use multiprocessing to calculate distances for each pair of cluster centers
    with Pool(cpu_count()) as pool:
        distances = pool.map(calculate_distances, pairs)

    # Average and median distances for the state
    if distances:
        avg_distance = np.mean(distances)
        median_distance = np.median(distances)

        return {'avg': avg_distance, 'median': median_distance}
    else:
        return None

# Assuming operational_hospitals is a pandas DataFrame with columns 'state', 'latitude', 'longitude', and 'operation_status'
operational_hospitals = filtered_gdf[filtered_gdf['operation_status'] == 'Operational']
unique_states = operational_hospitals['state'].unique()

state_distances = {}

for state in unique_states:
    state_distances[state] = calculate_state_distances(state, operational_hospitals)

print(state_distances)

state_distance_df = pd.DataFrame([(k, v['avg'], v['median']) for k, v in state_distances.items()], columns=['State', 'Average_m', 'Median_m'])
state_distance_df["Average_km"] = state_distance_df["Average_m"]*1.60934
state_distance_df["Median_km"] = state_distance_df["Median_m"]*1.60934
state_distance_df.head()

gdf.to_csv("nigerian_hosp_data_formatted.csv", index=False)
state_distance_df.to_csv("State_distances.csv", index=False)

""".

# **Column Exploration**
"""

gdf.info()









